{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13263bee-f929-48e8-b696-8cd374deb085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Zero-shot classification over file:\n",
    "- Input:  /projappl/project_2004147/visions/bertopic_with_zeroshot_chatgpt/df_geo_recoded_with_norm.csv\n",
    "- Output: /projappl/project_2004147/visions/bertopic_with_zeroshot_chatgpt/df_geo_recoded_with_norm_zeroshot.csv\n",
    "\n",
    "Adds columns with probabilities (no thresholds) using descriptive labels\n",
    "but saves them under the fixed names:\n",
    "  z_culture, z_nature, z_society, z_greenwashing, z_transformativeness\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ── Paths ─────────────────────────────────────────────────────────────────────\n",
    "BASE_DIR    = \"/projappl/project_2004147/visions/bertopic_with_zeroshot_chatgpt\"\n",
    "IN_CSV      = os.path.join(BASE_DIR, \"df_with_final_predictions.csv\")\n",
    "OUT_CSV     = os.path.join(BASE_DIR, \"df_with_final_predictions_zeroshot.csv\")\n",
    "\n",
    "# ── Labels & model ────────────────────────────────────────────────────────────\n",
    "\n",
    "# Define the descriptive labels for the model\n",
    "NATURE_LABEL = \"nature, wildlife, biodiversity, ecosystems, and landscapes\"\n",
    "SOCIETY_LABEL = \"green technology, business, industry, and natural resources\"\n",
    "CULTURE_LABEL = \"people, community values, and cultural heritage\"\n",
    "GREENWASHING_LABEL = \"corporate greenwashing and misleading environmental claims\"\n",
    "TRANSFORMATIVE_LABEL = \"fundamental reorganization of social and economic systems\"\n",
    "\n",
    "\n",
    "# This list is passed to the classification pipeline\n",
    "LABELS_FOR_MODEL = [\n",
    "    NATURE_LABEL,\n",
    "    SOCIETY_LABEL,\n",
    "    CULTURE_LABEL,\n",
    "    GREENWASHING_LABEL,\n",
    "    TRANSFORMATIVE_LABEL\n",
    "]\n",
    "\n",
    "# Map descriptive labels to your desired fixed column names\n",
    "COLUMN_MAP = {\n",
    "    NATURE_LABEL: \"z_nature\",\n",
    "    SOCIETY_LABEL: \"z_society\",\n",
    "    CULTURE_LABEL: \"z_culture\",\n",
    "    GREENWASHING_LABEL: \"z_greenwashing\",\n",
    "    TRANSFORMATIVE_LABEL: \"z_transformativeness\"\n",
    "}\n",
    "\n",
    "HYPOTHESIS_TEMPLATE = \"This text is about {}.\"   # classic NLI-style prompt\n",
    "MODEL_ID = \"facebook/bart-large-mnli\"\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# ── Helpers ───────────────────────────────────────────────────────────────────\n",
    "def pick_text_columns(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Prefer raw 'text' (better for NLI); fallback to 'text_clean' if needed.\"\"\"\n",
    "    if \"text\" in df.columns:\n",
    "        base = df[\"text\"].astype(str)\n",
    "        if \"text_clean\" in df.columns:\n",
    "            clean = df[\"text_clean\"].astype(str)\n",
    "            use = base.where(base.str.strip().ne(\"\"), clean)\n",
    "        else:\n",
    "            use = base\n",
    "    elif \"text_clean\" in df.columns:\n",
    "        use = df[\"text_clean\"].astype(str)\n",
    "    else:\n",
    "        raise KeyError(\"Neither 'text' nor 'text_clean' found in the input CSV.\")\n",
    "    use = use.str.replace(r\"http\\S+|www\\.\\S+\", \" \", regex=True)\n",
    "    use = use.str.replace(r\"(?:^|\\s)@[\\w_]+\", \" \", regex=True)\n",
    "    use = use.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    return use.fillna(\"\")\n",
    "\n",
    "# ── Load data ─────────────────────────────────────────────────────────────────\n",
    "df = pd.read_csv(IN_CSV, low_memory=False)\n",
    "texts = pick_text_columns(df)\n",
    "print(f\"Loaded {len(df):,} rows. Using column(s): {'text' if 'text' in df.columns else ''}{' + text_clean (fallback)' if 'text_clean' in df.columns else ''}\")\n",
    "\n",
    "# ── Zero-shot pipeline ────────────────────────────────────────────────────────\n",
    "device_id = 0 if torch.cuda.is_available() else -1\n",
    "clf = pipeline(\"zero-shot-classification\", model=MODEL_ID, device=device_id)\n",
    "\n",
    "# ── Run in batches and capture probabilities for each label ───────────────────\n",
    "# Initialize the results dictionary using the fixed column names\n",
    "z_cols = {col_name: [] for col_name in COLUMN_MAP.values()}\n",
    "\n",
    "for start in tqdm(range(0, len(texts), BATCH_SIZE), desc=\"Zero-shot batches\", unit=\"batch\"):\n",
    "    batch = texts.iloc[start:start + BATCH_SIZE].tolist()\n",
    "    out = clf(\n",
    "        batch,\n",
    "        candidate_labels=LABELS_FOR_MODEL,\n",
    "        hypothesis_template=HYPOTHESIS_TEMPLATE,\n",
    "        multi_label=True,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    if isinstance(out, dict):\n",
    "        out = [out]\n",
    "\n",
    "    for res in out:\n",
    "        # Create a map from the model's output labels to their scores\n",
    "        score_map = dict(zip(res[\"labels\"], res[\"scores\"]))\n",
    "        \n",
    "        # Use the COLUMN_MAP to populate the results with the correct column names\n",
    "        for model_label, column_name in COLUMN_MAP.items():\n",
    "            score = score_map.get(model_label, 0.0)\n",
    "            z_cols[column_name].append(float(score))\n",
    "\n",
    "# ── Attach to DF and save ─────────────────────────────────────────────────────\n",
    "for col, vals in z_cols.items():\n",
    "    df[col] = vals\n",
    "\n",
    "# The output CSV will now contain all five fixed-name columns\n",
    "df.to_csv(OUT_CSV, index=False, quoting=csv.QUOTE_MINIMAL)\n",
    "print(f\"Saved zero-shot scores to: {OUT_CSV}\")\n",
    "\n",
    "# ── Quick sanity check printout ───────────────────────────────────────────────\n",
    "print(\"\\nPreview of score columns (head):\")\n",
    "columns_to_preview = [\n",
    "    'z_nature',\n",
    "    'z_society',\n",
    "    'z_culture',\n",
    "    'z_greenwashing',\n",
    "    'z_transformativeness'\n",
    "]\n",
    "print(df[columns_to_preview].head().to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
